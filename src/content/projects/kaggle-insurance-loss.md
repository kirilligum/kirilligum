---
title: "Predicting insurance re loss (Kaggle competition)"
date: 2014-08-01
description: "Given 450K labeled samples with 300 features each, predict insurance loss on another 450K samples. [Python, pandas, sklearn, unbalanced data, missing values, feature importance, mixture of models] Using cross-validation on R^2, gini index and F1-score, I compared a number of combinations of procedures for features selections (Lasso, ensemble trees, PCA, SVM), data cleaning/transformations (one-hot, ordered/unordered, unbalanced), imputing missing values (mean, multiple imputation, GMM, ensemble methods), regression models (gradient boosted and extremely randomized trees), and stacking of different predictive models using averaging and non-linear regressions."
tags: ["Python", "pandas", "sklearn", "unbalanced data", "missing values", "feature importance", "mixture of models"]
---
